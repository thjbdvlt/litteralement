-- Note sur le modèle EAV hybride:
-- implémentation d'un modèle EAV hybride pour l'analyse de texte, avec une séparation stricte entre la partie EAV (entité, propriété, valeurs, relations, classe) et la partie relationnelle standard consacrée à l'analyse de textes (mots, segments, pos-tags, morphologies, etc.)
-- (un modèle EAV complet est souvent peu recommandé par la communauté des développeur·euses pour des raisons de performances, mais aussi de lisibilité des requêtes -- et dans le cas d'un travail académique, c'est peut-être cette seconde raison qui doit le plus décourager ce choix.)

create schema if not exists nlp;
create schema if not exists onto;

alter database litteralement set search_path to public, onto, nlp;

-- 1. EAV
-- les classes qui construisent l'ontologie de la partie EAV de la base de données. toutes ces classes ont la même structure, et c'est pourquoi elles sont toutes définies sur la base de la table 'classe'. quoi qu'elles soient toutes structurellement identiques, elles ont des positions différentes dans la base de données et accueillent des objets qui, eux aussi, ont des natures différentes, c'est pourquoi il ne me semble ni judicieux ni utile d'en faire une seule table (qui rendrait, en plus, les requêtes plus compliquées et nécessiterait l'utilisation d'index pour éviter des baisses de performances, quoique légères).

-- 1.1. les tables qui constituent l'ontologie: classes, types de propriétés et types de relation.

create table onto.class (
    id smallint primary key 
        generated by default as identity not null, 
    name text not null,
    definition text,
    unique (name)
);

create table onto.relation_type (like onto.class including all);

create table onto.attr_type (like onto.class including all);

-- 1.2. les tables qui contiennent les instances (entités, propriétés, relations, instance_a_tag, propriete_value) de la partie public.

create table public.entity (
    id int primary key 
        generated by default as identity not null, 
    class smallint references onto.class(id) not null
);

create table public.relation (
    id int primary key 
        generated by default as identity not null,
    type smallint references onto.relation_type(id) not null,
    sub int references public.entity(id) not null,
    obj int references public.entity(id) not null
);

create table public.attr (
    -- pour les propriétés qui ne nécessite aucune valeur, par exemple 'is_fictional'.
    type smallint references onto.attr_type(id),
    entity int references public.entity(id) not null
);

-- 1.2.1. les propriétés qui nécessitent des valeurs ont, pour chaque datatype, une table correspondante, qui hérite de la table propriété.

create table public.intattr (val int) inherits (public.attr);

create table public.floatattr (val float) inherits (public.attr);

create table public.dateattr (val timestamp) inherits (public.attr);

-- 1.3. la table qui fait la liaison entre les deux parties de la base de données (EAV et relationnel standard) est la table texte.

create table nlp.textattr(
    -- la table 'texte' est différente de la table 'prop_text' car elle contient des objets avec un identifiant, auquel peut faire référence les tables du schéma 'nlp'. (dans les faits, on va probablement tout mettre dans texte par simplicité.)
    id int primary key 
        generated by default as identity not null,
) inherits(attr);

-- 2. la partie relationnelle standard de la base de données, pour l'analyse linguistique qui se fait à l'aide de catégories, d'outils conceptuels indépendant des objets matériels et sociaux qui contiennent les textes.

-- 2.1. première partie décrit les mots possibles et les types de segment, elle est en quelque sorte idéale et abstraite.

create table nlp.dep (like onto.type_attr including all);

create table nlp.pos (like onto.type_attr including all);

create table nlp.morph (
    id smallint primary key
        generated by default as identity not null,
    feats text,
    j jsonb
);

create table nlp.lemma (
    id int primary key
        generated by default as identity not null,
    text text
);

create table nlp.lex (
    id int primary key
        generated by default as identity not null,
    lemma smallint references nlp.lemma (id) not null,
    pos smallint references nlp.pos(id) not null,
    morph smallint references nlp.morph(id) not null,
    norm text not null
);

-- 2.2. seconde partie décrit les mots et segments réels, utilisés dans des contextes (des textes).

create table nlp.span (
    text int references nlp.text(id) not null,
    startchar int not null,
    endchar int not null
);

create table nlp.span (attrs jsonb) inherits (nlp.span);

create table nlp.token (num int not null) inherits (nlp.span);

create table nlp.word(
    dep smallint references nlp.dep(id) not null,
    lex int references nlp.lex(id),
    head int
) inherits (nlp.token);


-- 3. enfin, un dernier schéma sert à ajouter les données.

create schema if not exists import;

create table import._data(
    j jsonb
);
create table import._doc(
    id int,
    j jsonb
);
